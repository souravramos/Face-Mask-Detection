{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport os\n!pip install mtcnn\nfrom mtcnn import MTCNN\nimport cv2\nimport json\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"lr = 1e-4\nbs = 32\nepochs = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annotations_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations/'\nimages_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimages=[]\nlabels=[]\nfor filename in os.listdir(images_dir):\n    num = filename.split('.')[ 0 ]\n    if int(num) > 1800:\n        class_name = None\n        anno = filename + \".json\"\n        with open(os.path.join(annotations_dir, anno)) as json_file:\n            json_data = json.load(json_file)\n            no_anno = json_data[\"NumOfAnno\"]\n            k = 0\n            for i in range(0, no_anno):\n                class_nam = json_data['Annotations'][i]['classname']\n                if class_nam == 'face_with_mask':\n                    class_name = 'face_with_mask'\n                    k = i\n                    break\n                elif class_nam == 'face_no_mask':\n                    class_name = 'face_no_mask'\n                    k = i\n                    break\n                else:\n                    if class_nam in ['hijab_niqab', 'face_other_covering', \"face_with_mask_incorrect\", \"scarf_bandana\", \"balaclava_ski_mask\", \"other\" ]:\n                        class_name = 'face_no_mask'\n                    elif class_nam in [\"gas_mask\", \"face_shield\", \"mask_surgical\", \"mask_colorful\"]:\n                        class_name = 'face_with_mask'\n            box = json_data[ 'Annotations' ][k][ 'BoundingBox' ]\n            (x1, x2, y1, y2) = box\n        if class_name is not None:\n            image = cv2.imread(os.path.join(images_dir, filename))\n            img = image[x2:y2, x1:y1]\n            img = cv2.resize(img, (224, 224))\n            img = img[...,::-1].astype(np.float32)\n            img = preprocess_input(img)\n            images.append(img)\n            labels.append(class_name)  \n   \nimages = np.array(images, dtype=\"float32\")\nlabels = np.array(labels)\nprint(len(images))\nprint(len(labels))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = LabelEncoder()\nlabels = lb.fit_transform(labels)\nprint(labels[:10])\nlabels = to_categorical(labels)\nprint(labels[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(trainX, testX, trainY, testY) = train_test_split(images, labels,\n                                test_size=0.20, stratify=labels, random_state=42)\nprint(len(trainX))\nprint(len(trainY))\nprint(len(testX))\nprint(len(testY))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimageData = ImageDataGenerator(rotation_range=20,\n                              zoom_range=0.15,\n                              width_shift_range=0.2,\n                              height_shift_range=0.2,\n                              shear_range=0.15,\n                              fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model1 = MobileNetV2(weights='imagenet',\n                    include_top=False,\n                    input_shape=(224,224,3))\nModel2 = Model1.output\nModel2 = AveragePooling2D(pool_size=(7,7))(Model2)\nModel2 = Flatten(name='flatten')(Model2)\nModel2 = Dense(128, activation='relu')(Model2)\nModel2 = Dropout(0.5)(Model2)\nModel2 = Dense(2, activation='softmax')(Model2)\nmodel = Model(inputs=Model1.input, outputs=Model2)\nfor layer in Model1.layers:\n    layer.trainable = False\noptimizer = Adam(lr=lr, decay=lr/epochs)\nmodel.compile(loss='binary_crossentropy', \n              optimizer=optimizer,\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"his = model.fit(imageData.flow(trainX, trainY, batch_size=bs),\n               steps_per_epoch=len(trainX)//bs,\n               validation_data=(testX, testY),\n               validation_steps=len(testX)//bs,\n               epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(his.history['accuracy'])\nplt.plot(his.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Accuracy')\nplt.ylabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(his.history['loss'])\nplt.plot(his.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Loss')\nplt.ylabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.predict(testX, batch_size=bs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(testX, batch_size=bs)\npred = np.argmax(pred, axis=1)\nprint(classification_report(testY.argmax(axis=1), pred, target_names=lb.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(os.path.join(images_dir, '1800.jpg'))\nx = cv2.rectangle(img, (956,460),(246,326), (0,55,155), 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detector = MTCNN()\nimg = plt.imread(os.path.join(images_dir, '1795.jpg'))\nface = detector.detect_faces(img)\nfor face in face:\n    bounding_box = face['box']\n    x=cv2.rectangle(img,\n                   (bounding_box[0], bounding_box[1]),\n                   (bounding_box[0]+bounding_box[2], \n                   bounding_box[1]+bounding_box[3]),\n                   (0, 155, 255),\n                   4)\n    plt.imshow(x)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = os.listdir(images_dir)\na.sort()\nprint((a))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = a[:1698]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detector = MTCNN()\ntest_df = []\nfor image in test_images:\n    img = plt.imread(os.path.join(images_dir, image))\n    faces = detector.detect_faces(img)\n    test = []\n    for face in faces:\n        bounding_box = face['box']\n        test.append([image, bounding_box])\n    test_df.append(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\nfor i in test_df:\n    if len(i)>0:\n        if len(i)==1:\n            test.append(i[0])\n        else:\n            for j in i:\n                test.append(j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=[]\nrest_image=[]\nfor i in test:\n    sub.append(i[0])\nfor image in test_images:\n    if image not in sub:\n        rest_image.append(image) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detector=MTCNN()\ntest_df_=[]\nfor image in rest_image:\n    img=cv2.imread(os.path.join(images_dir,image))\n    faces=detector.detect_faces(img)\n    test_=[]\n    for face in faces:\n        bounding_box=face['box']\n        test_.append([image,bounding_box])\n    test_df_.append(test_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in test_df_:\n    if len(i)>0:\n        if len(i)==1:\n            test.append(i[0])\n        else:\n            for j in i:\n                test.append(j) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative = []\nfor i in test:\n    for j in i[1]:\n        if j<0:\n            negative.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = []\ndef create_test_data():\n    for j in test:\n        if j not in negative:\n            img = cv2.imread(os.path.join(images_dir, j[0]))\n            img = img[j[1][1]:j[1][1]+j[1][3],\n                      j[1][0]:j[1][0]+j[1][2]]\n            img = cv2.resize(img, (224, 224))\n            img = img.reshape(-1,224,224,3)\n            img = preprocess_input(img)\n            predict = model.predict(img)\n            test_data.append([j, predict])\n    \ncreate_test_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = []\nclassname = []\nfor i,j in test_data:\n    classname.append(np.argmax(j))\n    image.append(i)\ndf = pd.DataFrame(columns=['image', 'classname'])\ndf['image']=image\ndf['classname']=classname\ndf['classname']= lb.inverse_transform(df['classname'])\n\nimage=[]\nx1=[]\nx2=[]\ny1=[]\ny2=[]\nfor i in df['image']:\n    image.append(i[0])\n    x1.append(i[1][0])\n    x2.append(i[1][1])\n    y1.append(i[1][2])\n    y2.append(i[1][3])\ndf['name'] = image\ndf['x1'] = x1\ndf['x2'] = x2\ndf['y1'] = y1\ndf['y2'] = y2\ndf.drop(['image'], axis=1, inplace=True)\ndf.sort_values('name', axis=0, inplace=True, ascending=False)\ncols = ['name', 'x1', 'x2', 'y1', 'y2', 'classname']\ndf = df[cols]\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}